result$choice <- factor(result$choice,levels = name[2:(nrow(y)+1)],ordered = TRUE)
# id <- 1:(dim(dat)[1])
library(vcrpart)
lmm <- olmm(choice~X2+X3+re(1|factor),data=result,family=cumulative())
# 데이터가 너무 많으면 오류?? -> b0의 문제?
# lmm <- olmm(Choice~ce(X2)+ce(X3)+ce(X4)+ce(X5),data=dat,family=baseline)
summary(lmm)
beta
rm(list=ls())
gc()
p <- 3  # 계수
k <- 3 # category
nt <- 3 # 각 시행 수
r <- 100 # 각 그룹별 수
g <- 30# 그룹 수
N = r*g
sigb = 1.5
# sigb=c(1.0,0.5,2,1.5,3)
require(Matrix)
require(MASS)
# mu=rep(0, g)
# Sigma=Diagonal(g,sigb)
# b <- matrix(rep(mvrnorm(n=1, mu=mu, Sigma=Sigma),each=(k-1)),nrow=g,byrow=TRUE)
b=matrix(rep(rnorm(g,0,sigb),each=(k-1)),nrow=g,byrow=TRUE)
# set.seed(111212711)
# b0 <- sort(round(runif(k-1)*(2.0)-1.0,2))
b0 <- c(-0.5,1.7)
beta <- matrix(c(b0,rep(round(runif(p-1)*2.0-1.0,2),each=(k-1))),nrow=p,byrow=TRUE)
f <- gl(g,r)
Z <- t(as(f,Class="sparseMatrix"))
# Jii <- diag(g)
# Z <- KhatriRao(Ji,Jii)
X <- matrix(rnorm(N*(p-1)),N,(p-1))
X <- cbind(1,X)
# X <- cbind(1,X)
eta <- X %*% beta + Z%*%b
mu <- matrix(rep(0,N*k),nrow=N)
for(i in 1:(k-1)){
mu[,i] <- 1/(1+exp(-eta[,i]))
}
if(k == 2){
mu[,2] <- 1- mu[,1]
}else{
mu[,2:(k-1)] <- mu[,2:(k-1)] - mu[,1:(k-2)]
mu[,k] <- 1 - apply(mu[,1:(k-1)],1,sum)
}
y = matrix(rep(0,N*k),nrow=k)
for(i in 1:N){
y[,i] <- rmultinom(size=nt,prob=mu[i,],n=1)
}
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
######### clmm2
library(tidyr)
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
name <- c("id",as.character(seq(1:dim(y)[1])),paste0('X',seq(1:ncol(X))),"factor")
colnames(dat) <- name
dat <- gather(data=dat,as.character(seq(1:dim(y)[1])),key="Choice",value="value")
dat <- dat[dat["value"]!=0,]
dat$factor <- as.character(dat$factor)
dat2 <- lapply(1:nrow(dat), function(x) matrix(as.character(dat[x, 1:(ncol(dat)-1)]), nrow = dat[x, ncol(dat)], ncol = (ncol(dat)-1), byrow = T))
result <- data.frame(do.call(rbind, dat2),stringsAsFactors=FALSE)
result <- as.data.frame(apply(result, 2, as.numeric))
colnames(result) <- c(name[-c(2:(nrow(y)+1))],"choice")
result$factor <- as.factor(result$factor)
result$choice <- factor(result$choice,levels = name[2:(nrow(y)+1)],ordered = TRUE)
# id <- 1:(dim(dat)[1])
library(vcrpart)
lmm <- olmm(choice~X2+X3+re(1|factor),data=result,family=cumulative())
# 데이터가 너무 많으면 오류?? -> b0의 문제?
# lmm <- olmm(Choice~ce(X2)+ce(X3)+ce(X4)+ce(X5),data=dat,family=baseline)
summary(lmm)
beta
rm(list=ls())
gc()
p <- 3  # 계수
k <- 3 # category
nt <- 3 # 각 시행 수
r <- 100 # 각 그룹별 수
g <- 30# 그룹 수
N = r*g
sigb = 1.5
# sigb=c(1.0,0.5,2,1.5,3)
require(Matrix)
require(MASS)
# mu=rep(0, g)
# Sigma=Diagonal(g,sigb)
# b <- matrix(rep(mvrnorm(n=1, mu=mu, Sigma=Sigma),each=(k-1)),nrow=g,byrow=TRUE)
b=matrix(rep(rnorm(g,0,sigb),each=(k-1)),nrow=g,byrow=TRUE)
# set.seed(111212711)
# b0 <- sort(round(runif(k-1)*(2.0)-1.0,2))
b0 <- c(-0.5,1.7)
beta <- matrix(c(b0,rep(round(runif(p-1)*2.0-1.0,2),each=(k-1))),nrow=p,byrow=TRUE)
f <- gl(g,r)
Z <- t(as(f,Class="sparseMatrix"))
# Jii <- diag(g)
# Z <- KhatriRao(Ji,Jii)
X <- matrix(rnorm(N*(p-1)),N,(p-1))
X <- cbind(1,X)
# X <- cbind(1,X)
eta <- X %*% beta + Z%*%b
mu <- matrix(rep(0,N*k),nrow=N)
for(i in 1:(k-1)){
mu[,i] <- 1/(1+exp(-eta[,i]))
}
if(k == 2){
mu[,2] <- 1- mu[,1]
}else{
mu[,2:(k-1)] <- mu[,2:(k-1)] - mu[,1:(k-2)]
mu[,k] <- 1 - apply(mu[,1:(k-1)],1,sum)
}
y = matrix(rep(0,N*k),nrow=k)
for(i in 1:N){
y[,i] <- rmultinom(size=nt,prob=mu[i,],n=1)
}
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
######### clmm2
library(tidyr)
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
name <- c("id",as.character(seq(1:dim(y)[1])),paste0('X',seq(1:ncol(X))),"factor")
colnames(dat) <- name
dat <- gather(data=dat,as.character(seq(1:dim(y)[1])),key="Choice",value="value")
dat <- dat[dat["value"]!=0,]
dat$factor <- as.character(dat$factor)
dat2 <- lapply(1:nrow(dat), function(x) matrix(as.character(dat[x, 1:(ncol(dat)-1)]), nrow = dat[x, ncol(dat)], ncol = (ncol(dat)-1), byrow = T))
result <- data.frame(do.call(rbind, dat2),stringsAsFactors=FALSE)
result <- as.data.frame(apply(result, 2, as.numeric))
colnames(result) <- c(name[-c(2:(nrow(y)+1))],"choice")
result$factor <- as.factor(result$factor)
result$choice <- factor(result$choice,levels = name[2:(nrow(y)+1)],ordered = TRUE)
# id <- 1:(dim(dat)[1])
library(vcrpart)
lmm <- olmm(choice~X2+X3+re(1|factor),data=result,family=cumulative())
# 데이터가 너무 많으면 오류?? -> b0의 문제?
# lmm <- olmm(Choice~ce(X2)+ce(X3)+ce(X4)+ce(X5),data=dat,family=baseline)
summary(lmm)
beta
rm(list=ls())
gc()
p <- 3  # 계수
k <- 3 # category
nt <- 3 # 각 시행 수
r <- 100 # 각 그룹별 수
g <- 30# 그룹 수
N = r*g
sigb = 1.5
# sigb=c(1.0,0.5,2,1.5,3)
require(Matrix)
require(MASS)
# mu=rep(0, g)
# Sigma=Diagonal(g,sigb)
# b <- matrix(rep(mvrnorm(n=1, mu=mu, Sigma=Sigma),each=(k-1)),nrow=g,byrow=TRUE)
b=matrix(rep(rnorm(g,0,sigb),each=(k-1)),nrow=g,byrow=TRUE)
# set.seed(111212711)
# b0 <- sort(round(runif(k-1)*(2.0)-1.0,2))
b0 <- c(-0.5,1.7)
beta <- matrix(c(b0,rep(round(runif(p-1)*2.0-1.0,2),each=(k-1))),nrow=p,byrow=TRUE)
f <- gl(g,r)
Z <- t(as(f,Class="sparseMatrix"))
# Jii <- diag(g)
# Z <- KhatriRao(Ji,Jii)
X <- matrix(rnorm(N*(p-1)),N,(p-1))
X <- cbind(1,X)
# X <- cbind(1,X)
eta <- X %*% beta + Z%*%b
mu <- matrix(rep(0,N*k),nrow=N)
for(i in 1:(k-1)){
mu[,i] <- 1/(1+exp(-eta[,i]))
}
if(k == 2){
mu[,2] <- 1- mu[,1]
}else{
mu[,2:(k-1)] <- mu[,2:(k-1)] - mu[,1:(k-2)]
mu[,k] <- 1 - apply(mu[,1:(k-1)],1,sum)
}
y = matrix(rep(0,N*k),nrow=k)
for(i in 1:N){
y[,i] <- rmultinom(size=nt,prob=mu[i,],n=1)
}
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
######### clmm2
library(tidyr)
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
name <- c("id",as.character(seq(1:dim(y)[1])),paste0('X',seq(1:ncol(X))),"factor")
colnames(dat) <- name
dat <- gather(data=dat,as.character(seq(1:dim(y)[1])),key="Choice",value="value")
dat <- dat[dat["value"]!=0,]
dat$factor <- as.character(dat$factor)
dat2 <- lapply(1:nrow(dat), function(x) matrix(as.character(dat[x, 1:(ncol(dat)-1)]), nrow = dat[x, ncol(dat)], ncol = (ncol(dat)-1), byrow = T))
result <- data.frame(do.call(rbind, dat2),stringsAsFactors=FALSE)
result <- as.data.frame(apply(result, 2, as.numeric))
colnames(result) <- c(name[-c(2:(nrow(y)+1))],"choice")
result$factor <- as.factor(result$factor)
result$choice <- factor(result$choice,levels = name[2:(nrow(y)+1)],ordered = TRUE)
# id <- 1:(dim(dat)[1])
library(vcrpart)
lmm <- olmm(choice~X2+X3+re(1|factor),data=result,family=cumulative())
# 데이터가 너무 많으면 오류?? -> b0의 문제?
# lmm <- olmm(Choice~ce(X2)+ce(X3)+ce(X4)+ce(X5),data=dat,family=baseline)
summary(lmm)
beta
rm(list=ls())
gc()
p <- 3  # 계수
k <- 3 # category
nt <- 3 # 각 시행 수
r <- 100 # 각 그룹별 수
g <- 30# 그룹 수
N = r*g
sigb = 1.5
# sigb=c(1.0,0.5,2,1.5,3)
require(Matrix)
require(MASS)
# mu=rep(0, g)
# Sigma=Diagonal(g,sigb)
# b <- matrix(rep(mvrnorm(n=1, mu=mu, Sigma=Sigma),each=(k-1)),nrow=g,byrow=TRUE)
b=matrix(rep(rnorm(g,0,sigb),each=(k-1)),nrow=g,byrow=TRUE)
# set.seed(111212711)
# b0 <- sort(round(runif(k-1)*(2.0)-1.0,2))
b0 <- c(-0.5,1.7)
beta <- matrix(c(b0,rep(round(runif(p-1)*2.0-1.0,2),each=(k-1))),nrow=p,byrow=TRUE)
f <- gl(g,r)
Z <- t(as(f,Class="sparseMatrix"))
# Jii <- diag(g)
# Z <- KhatriRao(Ji,Jii)
X <- matrix(rnorm(N*(p-1)),N,(p-1))
X <- cbind(1,X)
# X <- cbind(1,X)
eta <- X %*% beta + Z%*%b
mu <- matrix(rep(0,N*k),nrow=N)
for(i in 1:(k-1)){
mu[,i] <- 1/(1+exp(-eta[,i]))
}
if(k == 2){
mu[,2] <- 1- mu[,1]
}else{
mu[,2:(k-1)] <- mu[,2:(k-1)] - mu[,1:(k-2)]
mu[,k] <- 1 - apply(mu[,1:(k-1)],1,sum)
}
y = matrix(rep(0,N*k),nrow=k)
for(i in 1:N){
y[,i] <- rmultinom(size=nt,prob=mu[i,],n=1)
}
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
######### clmm2
library(tidyr)
dat <- data.frame(id=(1:dim(X)[1]),y=t(y),X,factor=f)
name <- c("id",as.character(seq(1:dim(y)[1])),paste0('X',seq(1:ncol(X))),"factor")
colnames(dat) <- name
dat <- gather(data=dat,as.character(seq(1:dim(y)[1])),key="Choice",value="value")
dat <- dat[dat["value"]!=0,]
dat$factor <- as.character(dat$factor)
dat2 <- lapply(1:nrow(dat), function(x) matrix(as.character(dat[x, 1:(ncol(dat)-1)]), nrow = dat[x, ncol(dat)], ncol = (ncol(dat)-1), byrow = T))
result <- data.frame(do.call(rbind, dat2),stringsAsFactors=FALSE)
result <- as.data.frame(apply(result, 2, as.numeric))
colnames(result) <- c(name[-c(2:(nrow(y)+1))],"choice")
result$factor <- as.factor(result$factor)
result$choice <- factor(result$choice,levels = name[2:(nrow(y)+1)],ordered = TRUE)
# id <- 1:(dim(dat)[1])
library(vcrpart)
lmm <- olmm(choice~X2+X3+re(1|factor),data=result,family=cumulative())
# 데이터가 너무 많으면 오류?? -> b0의 문제?
# lmm <- olmm(Choice~ce(X2)+ce(X3)+ce(X4)+ce(X5),data=dat,family=baseline)
summary(lmm)
beta
b0 <- c(-0.5,1.7)
beta <- matrix(c(b0,rep(round(runif(p-1)*2.0-1.0,2),each=(k-1))),nrow=p,byrow=TRUE)
beta
# The list of valid books
books <<- list("A Mid Summer Night's Dream" = "summer",
"The Merchant of Venice" = "merchant",
"Romeo and Juliet" = "romeo")
text <- readLines(sprintf("./%s.txt", 'romeo'),
encoding="UTF-8")
setwd('C:\\Users\\eunbi\\Documents\\R\\wordcloud')
text <- readLines(sprintf("./%s.txt", 'romeo'),
encoding="UTF-8")
text
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
library(tm)
library(memoise)
library(wordcloud)
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
m = as.matrix(myDTM)
head(m)
sort(rowSums(m), decreasing = TRUE)
kk<-sort(rowSums(m), decreasing = TRUE)
str(kk)
?data.frame
kk <- as.data.frame(kk,stringsAsFactors=FALSE)
str(kk)
head(kk)
head(rownames(kk))
kk <- data.frame(rownames(kk)="name",kk,stringsAsFactors=FALSE)
kk <- data.frame(rownames(kk),kk,stringsAsFactors=FALSE)
str(kk)
head(kk)
colnames(kk) <- c('name',value)
colnames(kk) <- c('name','value')
head(kk)
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
# m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
kk<-sort(rowSums(m), decreasing = TRUE)
kk <- as.data.frame(kk,stringsAsFactors=FALSE)
kk <- data.frame(rownames(kk),kk,stringsAsFactors=FALSE)
colnames(kk) <- c('name','value')
})
shiny::runApp()
runApp()
v <- getTermMatrix('romeo')
wordcloud2(v,fontFamily = 'Segoe UI',fontWeight = 'bold',
color='random-light',backgroundColor = 'dark',shape='star')
head(v)
v
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
# m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
kk<-sort(rowSums(m), decreasing = TRUE)
kk <- as.data.frame(kk,stringsAsFactors=FALSE)
kk <- data.frame(rownames(kk),kk,stringsAsFactors=FALSE)
colnames(kk) <- c('name','value')
return(kk)
})
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
load(file='C:\\Users\\eunbi\\Documents\\R\\wordcloud\\naver_api_blog.RData')
View(get_news)
View(get_words)
View(get_news)
View(get_words)
get_news <- function(id=id,secret=secret,query = query,display=display,start=start){
url <- 'https://openapi.naver.com/v1/search/blog.json'
# query <- URLencode(iconv(query,to="UTF-8"))
query <- URLencode(enc2utf8(query))
result <- GET(paste0(url,"?query=",query,'&display=',display,'&start=',as.character(start)), add_headers("X-Naver-Client-Id"=id,"X-Naver-Client-Secret" = secret))
contents<- content(result, as = "parsed")
Title <- NULL
Date <- NULL
# Description
for(i in 1:length(contents$items)){
item <- contents$items[[i]]
title <- item$title
title <- gsub('<b>|</b>|&quot;|&q','',title)
Title <- rbind(Title,title)
date <- item$postdate
Date <- rbind(Date,date)
}
Title <- gsub('<b>|</b>|&quot;|&q','',Title)
Date <- substr(Date,6,11)
newsdata <- data.frame(Title=Title,Date=Date,stringsAsFactors=FALSE)
# return(newsdata)
return(newsdata)
}
# start = 1
# 검색할 단어
# query <- '손예진'
get_words <- function(query){
id = 'hdrynIo6enkvLinS2zeL' # api id
secret = 'uyyKeSWG5d' # api password
Data <- NULL
data <- get_news(id=id,secret = secret,query=query,display='100',start=1)
Data <- rbind(Data,data)
for(j in 1:9){
data <- get_news(id=id,secret=secret,query=query,display = '100',start =(100*j+1))
Data <- rbind(Data,data)
}
# 페이지 바꿔가며 데이터 수집
Data <- as.data.frame(Data,stringsAsFactors=FALSE)
Data$Title <- gsub('\\[.*?\\]|\\(.*?\\)|\\&.*?\\;','',Data$Title)
# 지저분한 단어들 제거
Data$Title <- str_replace_all(Data$Title,'\\W',' ')
# 특수문자 제거
Data$Title <- toupper(Data$Title) # 영어 대문자
words <- extractNoun(Data$Title)
# 명사인 단어만 구분해서 저장
count<-as.data.frame(table(unlist(words)),stringsAsFactors = FALSE)
# 단어 빈도 추출
count$Var1<-gsub(' ','',count$Var1)
# 단어에 있는 불필요한 빈공간 지우기
count<-count[-grep(query,count$Var1),]
# 검색어는 제외시키기
count<-count[nchar(count$Var1)>2,]
# 단어 글자가 2개보다 많은 경우만 추출
return(count)
}
save(get_news,file='C:/Users/eunbi/Documents/R/wordcloud/get_news.RData')
save(get_words,file='C:/Users/eunbi/Documents/R/wordcloud/get_words.RData')
rm(list=ls())
runApp()
runApp()
runApp('C:/Users/eunbi/Dropbox/chicken_plus/Eunbi/shiny/shiny_chicken_time.R')
install.packages(c('flexdashboard','shinydashboard'))
runApp('C:/Users/eunbi/Dropbox/chicken_plus/Eunbi/shiny/shiny_chicken_time.R')
install.packages('tidyverse')
runApp('C:/Users/eunbi/Dropbox/chicken_plus/Eunbi/shiny/shiny_chicken_time.R')
### 전처리
load(file="C:/Users/eunbi/Dropbox/chicken_plus/Eunbi/shiny/result_list.RData")
View(result_list)
result_list[[1]]
rm(list=ls())
runApp()
runApp()
# query <- '유재석'
get_news <- function(id=id,secret=secret,query = query,display=display,start=start){
url <- 'https://openapi.naver.com/v1/search/blog.json'
# query <- URLencode(iconv(query,to="UTF-8"))
query <- URLencode(enc2utf8(query))
result <- GET(paste0(url,"?query=",query,'&display=',display,'&start=',as.character(start)), add_headers("X-Naver-Client-Id"=id,"X-Naver-Client-Secret" = secret))
contents<- content(result, as = "parsed")
Title <- NULL
Date <- NULL
# Description
for(i in 1:length(contents$items)){
item <- contents$items[[i]]
title <- item$title
title <- gsub('<b>|</b>|&quot;|&q','',title)
Title <- rbind(Title,title)
date <- item$postdate
Date <- rbind(Date,date)
}
Title <- gsub('<b>|</b>|&quot;|&q','',Title)
Date <- substr(Date,6,11)
newsdata <- data.frame(Title=Title,Date=Date,stringsAsFactors=FALSE)
# return(newsdata)
return(newsdata)
}
get_words <- function(query){
id = 'hdrynIo6enkvLinS2zeL' # api id
secret = 'uyyKeSWG5d' # api password
Data <- NULL
data <- get_news(id=id,secret = secret,query=query,display='100',start=1)
Data <- rbind(Data,data)
for(j in 1:9){
data <- get_news(id=id,secret=secret,query=query,display = '100',start =(100*j+1))
Data <- rbind(Data,data)
}
# 페이지 바꿔가며 데이터 수집
Data <- as.data.frame(Data,stringsAsFactors=FALSE)
Data$Title <- gsub('\\[.*?\\]|\\(.*?\\)|\\&.*?\\;','',Data$Title)
# 지저분한 단어들 제거
Data$Title <- str_replace_all(Data$Title,'\\W',' ')
# 특수문자 제거
Data$Title <- toupper(Data$Title) # 영어 대문자
words <- extractNoun(Data$Title)
# 명사인 단어만 구분해서 저장
count<-as.data.frame(table(unlist(words)),stringsAsFactors = FALSE)
# 단어 빈도 추출
count$Var1<-gsub(' ','',count$Var1)
# 단어에 있는 불필요한 빈공간 지우기
count<-count[-grep(query,count$Var1),]
# 검색어는 제외시키기
count<-count[nchar(count$Var1)>2,]
# 단어 글자가 2개보다 많은 경우만 추출
return(count)
}
runApp()
runApp()
rm(list=ls())
runApp()
load('C:/Users/eunbi/Documents/R/wordcloud/new/naver_api_blog.RData')
rm(list=ls())
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
